{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e0cb0ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\workspace\\dacon\\rock\\env\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import f1_score\n",
    "from tqdm.auto import tqdm\n",
    "import cv2\n",
    "import albumentations as A\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "from pathlib import Path\n",
    "import glob\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5fb1de8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.get_device_name()) if torch.cuda.is_available() else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7a60f53d",
   "metadata": {},
   "outputs": [],
   "source": [
    "CFG = {\n",
    "    'IMG_SIZE': 299,\n",
    "    'EPOCHS': 1,\n",
    "    'LEARNING_RATE': 3e-4,\n",
    "    'BATCH_SIZE': 16,\n",
    "    'SEED': 777\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ef936e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "seed_everything(CFG['SEED'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cdf6e462",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PadSquare(A.ImageOnlyTransform):\n",
    "    def __init__(self, value=0, always_apply=False, p=1.0):\n",
    "        super().__init__(always_apply, p)\n",
    "        self.value = value\n",
    "\n",
    "    def apply(self, image, **params):\n",
    "        h, w, c = image.shape\n",
    "        max_dim = max(h, w)\n",
    "        pad_h = max_dim - h\n",
    "        pad_w = max_dim - w\n",
    "        top = pad_h // 2\n",
    "        bottom = pad_h - top\n",
    "        left = pad_w // 2\n",
    "        right = pad_w - left\n",
    "        return cv2.copyMakeBorder(image, top, bottom, left, right, cv2.BORDER_CONSTANT, value=self.value)\n",
    "\n",
    "    def get_transform_init_args_names(self):\n",
    "        return (\"value\",)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8dde927e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, img_path_list, label_list, transforms=None):\n",
    "        self.img_path_list = img_path_list\n",
    "        self.label_list = label_list\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_path = self.img_path_list[index]\n",
    "        image = cv2.imread(img_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        if self.transforms:\n",
    "            image = self.transforms(image=image)['image']\n",
    "        if self.label_list is not None:\n",
    "            return image, self.label_list[index]\n",
    "        else:\n",
    "            return image\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_path_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "484c67f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_transform = A.Compose([\n",
    "    PadSquare(value=(0, 0, 0)),\n",
    "    A.Resize(CFG['IMG_SIZE'], CFG['IMG_SIZE']),\n",
    "    A.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5)),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "test_transform = train_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "afaa438f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, latent_dim=128):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, 3, 1, 1), nn.BatchNorm2d(32), nn.ReLU(), nn.MaxPool2d(2),\n",
    "            nn.Conv2d(32, 64, 3, 1, 1), nn.BatchNorm2d(64), nn.ReLU(), nn.MaxPool2d(2),\n",
    "            nn.Conv2d(64, 128, 3, 1, 1), nn.BatchNorm2d(128), nn.ReLU(), nn.AdaptiveAvgPool2d((1, 1))\n",
    "        )\n",
    "        self.fc = nn.Linear(128, latent_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return self.fc(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ac176826",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "    def __init__(self, latent_dim=128, num_classes=7):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Linear(latent_dim, num_classes)\n",
    "\n",
    "    def forward(self, z):\n",
    "        return self.fc(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "25a67f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoClassifierUnit(nn.Module):\n",
    "    def __init__(self, latent_dim=128, num_classes=7):\n",
    "        super().__init__()\n",
    "        self.generator = Generator(latent_dim)\n",
    "        self.classifier = Classifier(latent_dim, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        z = self.generator(x)\n",
    "        return z, self.classifier(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a958ea4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CooperativeAutoClassifier(nn.Module):\n",
    "    def __init__(self, latent_dim=128, num_classes=7):\n",
    "        super().__init__()\n",
    "        self.acus = nn.ModuleList([AutoClassifierUnit(latent_dim, num_classes) for _ in range(3)])\n",
    "\n",
    "    def forward(self, x):\n",
    "        zs, logits_list = [], []\n",
    "        for acu in self.acus:\n",
    "            z, logits = acu(x)\n",
    "            zs.append(z)\n",
    "            logits_list.append(logits)\n",
    "        return zs, logits_list\n",
    "\n",
    "    def compute_loss(self, logits_list, zs, labels, lambda_coop=0.1):\n",
    "        ce_loss = sum(F.cross_entropy(logits, labels) for logits in logits_list) / len(logits_list)\n",
    "        coop_loss = sum(F.mse_loss(zs[i], zs[j]) for i in range(len(zs)) for j in range(i + 1, len(zs)))\n",
    "        coop_loss = 2 * coop_loss / (len(zs) * (len(zs) - 1))\n",
    "        return ce_loss + lambda_coop * coop_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4765dcee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_fn(model, train_loader, val_loader, optimizer, device, epochs):\n",
    "    model.to(device)\n",
    "    best_f1, best_model = 0, None\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        model.train()\n",
    "        train_losses = []\n",
    "        for imgs, labels in tqdm(train_loader, desc=f\"Epoch {epoch}\"):\n",
    "            imgs, labels = imgs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            zs, logits_list = model(imgs)\n",
    "            loss = model.compute_loss(logits_list, zs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_losses.append(loss.item())\n",
    "        val_f1 = validate(model, val_loader, device)\n",
    "        print(f\"Epoch {epoch}: Train Loss={np.mean(train_losses):.4f}, Val F1={val_f1:.4f}\")\n",
    "        if val_f1 > best_f1:\n",
    "            best_f1 = val_f1\n",
    "            best_model = model.state_dict()\n",
    "            \n",
    "            save_path = \"best_model(cac).pth\"\n",
    "            torch.save(best_model, save_path)\n",
    "            print(f\"Best model saved (epoch {epoch}, F1={val_f1:.4f}) → {save_path}\")\n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ad16c487",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, val_loader, device):\n",
    "    model.eval()\n",
    "    preds, targets = [], []\n",
    "    with torch.no_grad():\n",
    "        for imgs, labels in val_loader:\n",
    "            imgs = imgs.to(device)\n",
    "            zs, logits_list = model(imgs)\n",
    "            avg_logits = sum(logits_list) / len(logits_list)\n",
    "            preds.extend(avg_logits.argmax(1).cpu().numpy())\n",
    "            targets.extend(labels.numpy())\n",
    "    return f1_score(targets, preds, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ad77901b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(model, test_loader, device, label_encoder):\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    with torch.no_grad():\n",
    "        for imgs in tqdm(test_loader):\n",
    "            imgs = imgs.to(device)\n",
    "            _, logits_list = model(imgs)\n",
    "            avg_logits = sum(logits_list) / len(logits_list)\n",
    "            pred_labels = avg_logits.argmax(1).cpu().numpy().tolist()\n",
    "            preds.extend(pred_labels)\n",
    "    return label_encoder.inverse_transform(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f1d9ad30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and prepare data\n",
    "df = pd.DataFrame({'img_path': glob.glob('./train/*/*')})\n",
    "df['rock_type'] = df['img_path'].apply(lambda x: Path(x).parts[-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6cb6d90a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                      img_path       rock_type\n",
      "0             ./train\\Andesite\\TRAIN_00000.jpg        Andesite\n",
      "1             ./train\\Andesite\\TRAIN_00001.jpg        Andesite\n",
      "2             ./train\\Andesite\\TRAIN_00002.jpg        Andesite\n",
      "3             ./train\\Andesite\\TRAIN_00003.jpg        Andesite\n",
      "4             ./train\\Andesite\\TRAIN_00004.jpg        Andesite\n",
      "...                                        ...             ...\n",
      "380015  ./train\\Weathered_Rock\\TRAIN_37164.jpg  Weathered_Rock\n",
      "380016  ./train\\Weathered_Rock\\TRAIN_37165.jpg  Weathered_Rock\n",
      "380017  ./train\\Weathered_Rock\\TRAIN_37166.jpg  Weathered_Rock\n",
      "380018  ./train\\Weathered_Rock\\TRAIN_37167.jpg  Weathered_Rock\n",
      "380019  ./train\\Weathered_Rock\\TRAIN_37168.jpg  Weathered_Rock\n",
      "\n",
      "[380020 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "88f4bfa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_df, val_df = train_test_split(df, test_size=0.2, stratify=df['rock_type'], random_state=CFG['SEED'])\n",
    "le = preprocessing.LabelEncoder()\n",
    "train_df['rock_type'] = le.fit_transform(train_df['rock_type'])\n",
    "val_df['rock_type'] = le.transform(val_df['rock_type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7166fbb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CustomDataset(train_df['img_path'].values, train_df['rock_type'].values, train_transform)\n",
    "val_dataset = CustomDataset(val_df['img_path'].values, val_df['rock_type'].values, test_transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=CFG['BATCH_SIZE'], shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=CFG['BATCH_SIZE'], shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "25d29a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CooperativeAutoClassifier(latent_dim=128, num_classes=7)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=CFG['LEARNING_RATE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "750a95c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#학습코드드\n",
    "best_weights = train_fn(model, train_loader, val_loader, optimizer, device, CFG['EPOCHS'])\n",
    "model.load_state_dict(best_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5506b108",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load(\"best_model(cac).pth\", map_location=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0567f798",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "99b9b6b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5938/5938 [3:30:31<00:00,  2.13s/it]  \n"
     ]
    }
   ],
   "source": [
    "test_df = pd.read_csv('./test.csv')\n",
    "test_dataset = CustomDataset(test_df['img_path'].values, None, test_transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=CFG['BATCH_SIZE'], shuffle=False)\n",
    "preds = inference(model, test_loader, device, le)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4cf04cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = pd.read_csv('./sample_submission.csv')\n",
    "submit['rock_type'] = preds\n",
    "submit.to_csv('./baseline_submit(cac).csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
