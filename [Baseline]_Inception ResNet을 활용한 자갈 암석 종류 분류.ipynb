{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random # 랜덤함수\n",
    "import pandas as pd #데이터프레임\n",
    "import numpy as np #수치계산\n",
    "import os #파일이나 폴더 경로 다룰때\n",
    "import re # 정규표현식\n",
    "import glob #특정 경로의 파일들 리스트로 가져오기\n",
    "import cv2 #OpenCV: 이미지 불러오기 및 전처리\n",
    "import timm #파이토치 기반 최신 이미지 모델 모음(ResNet등)\n",
    "\n",
    "import torch #파이토치\n",
    "import torch.nn as nn #모델 구성(레이어, 손실함수)\n",
    "import torch.optim as optim #옵티마이저(아담)\n",
    "import torch.nn.functional as F #활성화 함수, Loss함수수\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler \n",
    "#사용자 정의 데이터셋 상속, 배치단위 데이터 불러오기, 클래스 불균형시 오버샘플링 사용\n",
    "# 아래는 이미지 전처리\n",
    "import albumentations as A #강력한 이미지 증강 라이브러리\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "from albumentations.core.transforms_interface import ImageOnlyTransform\n",
    "import torchvision.models as models #기본 cnn모델들, ResNet등\n",
    "\n",
    "from sklearn.model_selection import train_test_split #훈련/검증 나누기\n",
    "from sklearn import preprocessing #라벨 인코딩\n",
    "from sklearn.metrics import f1_score #성능 평가\n",
    "from sklearn.metrics import classification_report #성능 평가\n",
    "from tqdm.auto import tqdm #루프의 진행 상황을 한눈에 보기\n",
    "\n",
    "import warnings #경고 메세지 안보이게\n",
    "warnings.filterwarnings(action='ignore') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "NVIDIA GeForce GTX 1660 SUPER\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "# 현재 gpu가 활성화 됐는지 확인\n",
    "# false 일경우 cpu쓰기3\n",
    "print(torch.cuda.is_available())      # True여야 정상\n",
    "print(torch.cuda.get_device_name())  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "CFG = { #딕셔너리, 하이퍼파리미터를 모아놓음. config 설정값\n",
    "    #'IMG_SIZE':299, #299x299 리사이즈\n",
    "    'IMG_SIZE':224, #resnet50 사이즈\n",
    "    'EPOCHS':2, #학습 데이터셋 몇번 반복해서 학습할지\n",
    "    'LEARNING_RATE':3e-4,# 0.0003 모델 가중치 조절. 학습률\n",
    "    'BATCH_SIZE':16, #한번에 처리할 데이터 수. 원래 32\n",
    "    'SEED':41 #난수 생성 시드값\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed) #파이썬 내장 난수\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed) #해시 기반 연산-시드 영향 받게 환경변수 고정\n",
    "    np.random.seed(seed) #넘파이 기반 난수 함수\n",
    "    torch.manual_seed(seed) #파이토치에서 cpu 텐서 연산시 고정\n",
    "    torch.cuda.manual_seed(seed) #파이토치에서 gpu 연산시 고정\n",
    "    torch.backends.cudnn.deterministic = True #cnn 연산시 완전 동일한 연산 패턴 보장\n",
    "    torch.backends.cudnn.benchmark = True #입력 사이즈 고정시 연산속도 최적화 가능(위와 충돌할수)\n",
    "\n",
    "seed_everything(CFG['SEED']) # Seed 고정\n",
    "#이 셀로 인해 같은 코드 + 같은 데이터로 같은 결과를 얻게 만드는 목적\n",
    "#baseline을 기준으로 성능 비교 실험을 공정하게 하기위해.\n",
    "#운빨요소 제거"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_img_list = glob.glob('./train/*/*')\n",
    "#glob : 경로기반의 파일 리스트를 문자열로 가져오는 도구\n",
    "#*/*는 두단계 하위 경로까지 검색색"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "380020\n",
      "['./train\\\\Granite\\\\TRAIN_39303.jpg', './train\\\\Granite\\\\TRAIN_13720.jpg', './train\\\\Gneiss\\\\TRAIN_34416.jpg', './train\\\\Gneiss\\\\TRAIN_00504.jpg', './train\\\\Granite\\\\TRAIN_41720.jpg']\n"
     ]
    }
   ],
   "source": [
    "print(len(all_img_list))\n",
    "print(random.sample(all_img_list, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=['img_path', 'rock_type']) #df생성. 경로랑 락 타입 지정\n",
    "df['img_path'] = all_img_list\n",
    "#df['rock_type'] = df['img_path'].apply(lambda x : str(x).split('/')[2])\n",
    "# 경로포맷 \"\\\\\" 로 저장될수도 있다. \"/\" 이거안먹히면 아래꺼꺼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "df['rock_type'] = df['img_path'].apply(lambda x: Path(x).parts[-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                      img_path       rock_type\n",
      "0             ./train\\Andesite\\TRAIN_00000.jpg        Andesite\n",
      "1             ./train\\Andesite\\TRAIN_00001.jpg        Andesite\n",
      "2             ./train\\Andesite\\TRAIN_00002.jpg        Andesite\n",
      "3             ./train\\Andesite\\TRAIN_00003.jpg        Andesite\n",
      "4             ./train\\Andesite\\TRAIN_00004.jpg        Andesite\n",
      "...                                        ...             ...\n",
      "380015  ./train\\Weathered_Rock\\TRAIN_37164.jpg  Weathered_Rock\n",
      "380016  ./train\\Weathered_Rock\\TRAIN_37165.jpg  Weathered_Rock\n",
      "380017  ./train\\Weathered_Rock\\TRAIN_37166.jpg  Weathered_Rock\n",
      "380018  ./train\\Weathered_Rock\\TRAIN_37167.jpg  Weathered_Rock\n",
      "380019  ./train\\Weathered_Rock\\TRAIN_37168.jpg  Weathered_Rock\n",
      "\n",
      "[380020 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val, _, _ = train_test_split( #_, _ 이건 test split 추가여지 남긴것\n",
    "    df, \n",
    "    df['rock_type'], \n",
    "    test_size=0.3, #전체의 30%를 validation으로\n",
    "    stratify=df['rock_type'], # 클래스 비율을 유지한채 분리\n",
    "    random_state=CFG['SEED']) # 재현 가능한 split위해 시드고정\n",
    "#train_test_split()함수는 기본적으로 : (X_train, X_test, y_train, y_test형태로 4개 반환)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = preprocessing.LabelEncoder() # 문자열 라벨을 숫자로 바꿈\n",
    "train['rock_type'] = le.fit_transform(train['rock_type']) #처음엔 학습 + 변환\n",
    "val['rock_type'] = le.transform(val['rock_type']) #이미 학습된 매핑 그대로 숫자 변환"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 클래스 이름들은 다 문자열. 하지만 파이토치는 라벨을 숫자로 바꿔줘야 한다.\n",
    "- 문자열 라벨을 정수라벨로 바꿀때 LabelEncoder을 쓴다\n",
    "- train셋에 fit_transform()으로 라벨을 바꿔주고\n",
    "    - fit()으로 클래스의 라벨들을 학습(매핑) 해주고, transform()으로 매핑한 그대로 문자열을 정수로 바꾸는것 두개를 합친함수다.\n",
    "- 같은 클래스 숫자를 똑같이 val에도 해줘야 하니, transform()을 써줌줌"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 이미지 전처리. 패딩으로 정사각형 만든후 리사이징\n",
    "- value = 0. 패딩을 0으로 채우면 검정색으로 채워진다.\n",
    "- 굳이 이렇게 해야하나? 가운데만 잘라서 쓰면 안되나? 어차피 자갈인데(CenterCrop) 이란걸 쓰면 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PadSquare(ImageOnlyTransform): #이미지에 패딩 추가. 이미지별로 사이즈가 다르니 비율유지. 패딩으로 정사각형 만들고 resize함. ImageOnlyTransform 상속속\n",
    "    def __init__(self, border_mode=0, value=0, always_apply=False, p=1.0):\n",
    "        super().__init__(always_apply, p)\n",
    "        self.border_mode = border_mode\n",
    "        self.value = value\n",
    "\n",
    "    def apply(self, image, **params):\n",
    "        h, w, c = image.shape\n",
    "        max_dim = max(h, w)\n",
    "        pad_h = max_dim - h\n",
    "        pad_w = max_dim - w\n",
    "        top = pad_h // 2\n",
    "        bottom = pad_h - top\n",
    "        left = pad_w // 2\n",
    "        right = pad_w - left\n",
    "        image = cv2.copyMakeBorder(image, top, bottom, left, right, cv2.BORDER_CONSTANT, value=self.value) #이미지 테두리 확장함수수\n",
    "        return image\n",
    "\n",
    "    def get_transform_init_args_names(self):\n",
    "        return (\"border_mode\", \"value\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 파일경로, 라벨 받아서 이미지 읽고 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, img_path_list, label_list, transforms=None):\n",
    "        self.img_path_list = img_path_list\n",
    "        self.label_list = label_list\n",
    "        self.transforms = transforms\n",
    "        \n",
    "    def __getitem__(self, index): #이미지 가져와서 BGR을 RGB로 전환환\n",
    "        img_path = self.img_path_list[index]\n",
    "        \n",
    "        image = cv2.imread(img_path) # OpenCV는 BGR 형식이다.\n",
    "        \n",
    "        if self.transforms is not None: #만약 transform이 주어지면 이미지 전처리 끝내기기\n",
    "            image = self.transforms(image=image)['image']\n",
    "        \n",
    "        if self.label_list is not None: #라벨 있으면 train, val 상황. 없으면 test 상황. 이미지만 만환환\n",
    "            label = self.label_list[index]\n",
    "            return image, label\n",
    "        else:\n",
    "            return image\n",
    "        \n",
    "    def __len__(self): #데이터셋 크기 반환환\n",
    "        return len(self.img_path_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = A.Compose([\n",
    "    PadSquare(value=(0, 0, 0)), # 이미지 가로 세로중 긴쪽으로 패딩추가해 정사각형 맞추기기\n",
    "    A.Resize(CFG['IMG_SIZE'], CFG['IMG_SIZE']), # 리사이즈. 299사이즈네 현재.\n",
    "    A.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5)), #이미지 정규화\n",
    "    ToTensorV2() #파이토치 텐서로 전환환\n",
    "])\n",
    "\n",
    "test_transform = A.Compose([\n",
    "    PadSquare(value=(0, 0, 0)),\n",
    "    A.Resize(CFG['IMG_SIZE'], CFG['IMG_SIZE']),\n",
    "    A.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5)),\n",
    "    ToTensorV2()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CustomDataset(\n",
    "    train['img_path'].values, \n",
    "    train['rock_type'].values, \n",
    "    train_transform)\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size = CFG['BATCH_SIZE'], \n",
    "    shuffle=False, \n",
    "    num_workers=0, #원래 4\n",
    "    pin_memory=False, #원래 True\n",
    "    #prefetch_factor=2)\n",
    ")\n",
    "# 한번에 학습시킬 이미지수(배치사이즈), 셔플은 하지않음, 트레인에선 True를 해야 오버피팅 막는데 좋다.\n",
    "val_dataset = CustomDataset(\n",
    "    val['img_path'].values, \n",
    "    val['rock_type'].values, \n",
    "    test_transform)\n",
    "val_loader = DataLoader(\n",
    "    val_dataset, \n",
    "    batch_size=CFG['BATCH_SIZE'], \n",
    "    shuffle=False, \n",
    "    num_workers=0, #원래4\n",
    "    pin_memory=False, #원래 True\n",
    "    #prefetch_factor=2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, train_loader, val_loader, scheduler, device):\n",
    "    model.to(device)\n",
    "    criterion = nn.CrossEntropyLoss().to(device) #다중클래스 분류에서 쓰이는 손실함수.\n",
    "    \n",
    "    best_score = 0 #F1 스코어 기준 최고모델 저장\n",
    "    best_model = None\n",
    "    save_path = \"best_model.pth\"\n",
    "\n",
    "    for epoch in range(1, CFG['EPOCHS'] + 1): #에퐄 1부터 반복\n",
    "        model.train() #학습 시작\n",
    "        train_loss = []\n",
    "\n",
    "        for imgs, labels in tqdm(iter(train_loader), desc=f\"Epoch {epoch}\"): #tqdm 진행상황 시각화\n",
    "            imgs = imgs.float().to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad() #기존 그래디언트 초기화\n",
    "            output = model(imgs) #예측값 생성\n",
    "            loss = criterion(output, labels) #예측값, 실제값 비교. 오차.\n",
    "\n",
    "            loss.backward() #오차 역전파. 그래디언트 계산\n",
    "            optimizer.step() #가중치 갱신(SGD나 아담 등등)\n",
    "\n",
    "            train_loss.append(loss.item()) #로스 숫자만큼 추출해 리스트 저장장\n",
    "\n",
    "        _val_loss, _val_score = validation(model, criterion, val_loader, device)\n",
    "        _train_loss = np.mean(train_loss)\n",
    "\n",
    "        print(f'Epoch [{epoch}], Train Loss: {_train_loss:.5f}, Val Loss: {_val_loss:.5f}, Val Macro F1: {_val_score:.5f}')\n",
    "\n",
    "        if scheduler is not None:\n",
    "            scheduler.step(_val_score)\n",
    "\n",
    "        if best_score < _val_score:\n",
    "            best_score = _val_score\n",
    "            best_model = model\n",
    "\n",
    "            # 모델 가중치 저장\n",
    "            torch.save(model.state_dict(), save_path)\n",
    "            print(f\"Best model saved (epoch {epoch}, F1={_val_score:.4f}) → {save_path}\")\n",
    "\n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(model, criterion, val_loader, device):\n",
    "    model.eval()\n",
    "    val_loss = []\n",
    "    preds, true_labels = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for imgs, labels in tqdm(iter(val_loader)):\n",
    "            imgs = imgs.float().to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            pred = model(imgs)\n",
    "            \n",
    "            loss = criterion(pred, labels)\n",
    "            \n",
    "            preds += pred.argmax(1).detach().cpu().numpy().tolist()\n",
    "            true_labels += labels.detach().cpu().numpy().tolist()\n",
    "            \n",
    "            val_loss.append(loss.item())\n",
    "        \n",
    "        _val_loss = np.mean(val_loss)\n",
    "        _val_score = f1_score(true_labels, preds, average='macro')\n",
    "    \n",
    "    return _val_loss, _val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 16626/16626 [56:16<00:00,  4.92it/s] \n",
      "100%|██████████| 7126/7126 [25:04<00:00,  4.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1], Train Loss: 0.68371, Val Loss: 0.51542, Val Macro F1: 0.75642\n",
      "Best model saved (epoch 1, F1=0.7564) → best_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 16626/16626 [57:58<00:00,  4.78it/s] \n",
      "100%|██████████| 7126/7126 [21:42<00:00,  5.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2], Train Loss: 0.49512, Val Loss: 0.49535, Val Macro F1: 0.77247\n",
      "Best model saved (epoch 2, F1=0.7725) → best_model.pth\n"
     ]
    }
   ],
   "source": [
    "#model = timm.create_model('inception_resnet_v2', pretrained=True, num_classes=7)\n",
    "model = timm.create_model(\n",
    "    'resnet18', \n",
    "    pretrained=True, \n",
    "    num_classes=7)\n",
    "\n",
    "optimizer = torch.optim.Adam(\n",
    "    params = model.parameters(), \n",
    "    lr = CFG[\"LEARNING_RATE\"])\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, \n",
    "    mode='max', \n",
    "    factor=0.5, \n",
    "    patience=2, \n",
    "    threshold_mode='abs', \n",
    "    min_lr=1e-8)#, verbose=True)\n",
    "\n",
    "infer_model = train(model, optimizer, train_loader, val_loader, scheduler, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('./test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = CustomDataset(test['img_path'].values, None, test_transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=CFG['BATCH_SIZE'], shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(model, test_loader, device):\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    with torch.no_grad():\n",
    "        for imgs in tqdm(iter(test_loader)):\n",
    "            imgs = imgs.float().to(device)\n",
    "            \n",
    "            pred = model(imgs)\n",
    "            \n",
    "            preds += pred.argmax(1).detach().cpu().numpy().tolist()\n",
    "    \n",
    "    preds = le.inverse_transform(preds)\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5938/5938 [19:43<00:00,  5.02it/s]\n"
     ]
    }
   ],
   "source": [
    "preds = inference(model, test_loader, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = pd.read_csv('./sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit['rock_type'] = preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit.to_csv('./baseline_submit.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rock",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
